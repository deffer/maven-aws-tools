= AWS tools maven plugin (S3 upload)

At the moment only supports upload of resources to S3 bucket.

== Usage

* Set up your preferred way of supplying AWS credentials
* Configure plugin in then pom
* Run `mvn aws-tools:upload`

For example, the minimal configuration below will upload file `background.jpg` into `castle-public` bucket. Credentials will bee looked in the `USER_HOME/.aws/credentials` file.

 <build>
 	<pluginManagement>
 		<plugins>
 			<plugin>
 				<groupId>net.deffer.maven</groupId>
 				<artifactId>aws-tools-maven-plugin</artifactId>
 				<version>1.2</version>
 				<extensions>true</extensions>
 				<configuration>
 					<source>background.jpg</source>
 					<bucketName>castle-public</bucketName>
 				</configuration>
 			</plugin>
 		</plugins>
 	</pluginManagement>
 </build>

To upload several files, use

 <configuration>
    <sources>
 	    <source>background.jpg</source>
 	    <source>tile.jpg</source>
    </sources>
 	<bucketName>castle-public</bucketName>
 </configuration>

== Description

Can upload 1 file, list of files, content of 1 folder, content on several folders into one `destination` (folder).

When uploading folder, only its content is uploaded (not the folder itself). With `recursive=true` it will include sub-folders (with their original names).
For example, this directory layout

 my-app
 |-- pom.xml
 |-- assets.zip
 `-- ASSETS
     |-- castle.jpg
     |-- welcome.jpg
     `-- IMAGES
         |-- a.png
         `-- b.png

and this configuration

 <bucketName>castle-public</bucketName>
 <destination>data</destination>
 <recursive>true</recursive>
 <sources>
    <source>assets.zip</source>
    <source>ASSETS</source>
 </sources>

will result in next S3 structure

 data/assets.zip
 data/castle.jpg
 data/welcome.jpg
 data/IMAGES/a.png
 data/IMAGES/b.png


When uploading file or list of files, there is an option to add a `suffix` to each file name (ex. version)

When uploading single file using `source` (not list of sources), `destination` is treated as new file name.

Path to files/folders is relative to current working dir.

=== Limitations

Only one bucket and one destination folder can be configured per execution.

No metadata support. No ACL support.

Suffix only supported for files (single or list) but not in folders

=== Known bugs

Sometimes it reports `0 bytes transferred` although upload completed successfully.

== Configuration

[cols="1,1,2"]
.Parameters
|===
|Name |Required |Description

|bucketName
|yes
|name of the bucket in S3, ex. `my-public-bucket`

|credentialProvider
|no +
_(default file)_
|`env \| java \| file \| instance \| provided`. See description below.

|source
|yes* _(either source or sources)_
|name of the single file to upload

|sources
|yes* _(either source or sources)_
|list of files/folders to upload

|destination
|no
|if only one source is defined, destination means new (S3) file name. otherwise its treated as name of "subfolder" in the bucket where files/folders will be copied to

|recursive
|no +
_(default false)_
|when uploading folder, indicates whether inner folders should be uploaded too

|suffix
|no
|when uploading files (no folders), suffix is added to the end of destination filename. can be used as version.

|dryRun
|no +
_(default false)_
|Skips the actual upload. Use it to test your configuration before running it.

|accessKey,
secretKey
|no
|only required when credentialProvider is `provided`
|===

== Credentials options

The `credentialProvider` configuration has following options (which corresponds to those described 
http://docs.aws.amazon.com/AWSSdkDocsJava/latest//DeveloperGuide/credentials.html[here]
and http://docs.aws.amazon.com/AWSSdkDocsJava/latest//DeveloperGuide/java-dg-setup.html#set-up-creds[here])

env:: 
through environment `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`
java::
through java system properties `aws.accessKeyId` and `aws.secretKey`
file::  
in the credentials file at `<USER_HOME>/.aws/credentials`

 [default]
 aws_access_key_id = AKAIAJT6FPYEQJN4J1EK
 aws_secret_access_key = dyunreKhlo7M655hNGoiHm7f63r1ccm0fJbhJg1z
 
instance::  
through the Amazon EC2 metadata service (only when running on EC2 instances)
provided::
configured in pom (not recommended)

 <configuration>
 	<credentialProvider>provided</credentialProvider>
 	<accessKey>AKAIAJT6FPYEQJN4J1EK</accessKey> 	
 	<secretKey>dyunreKhlo7M655hNGoiHm7f63r1ccm0fJbhJg1z</secretKey>
 </configuration>
 
== Examples

Upload file `assets.zip` as `assets.dat` into castle-public bucket

 <configuration>
  <bucketName>castle-public</bucketName>
  <source>assets.zip</source>
  <destination>assets.dat</destination>
 </configuration>

Upload `assets.zip` from `target` folder into subfolder `resources` adding project version as name suffix

 <configuration>
    <bucketName>castle-public</bucketName>
    <sources>
        <source>${project.build.directory}/assets.zip</source>
    </sources>
    <suffix>-${project.version}</suffix>
    <destination>resources</destination>
 </configuration>

Upload files `assets.zip` and `assets.meta` into castle-public adding version to their names

 <configuration>
    <bucketName>castle-public</bucketName>
    <sources>
        <source>assets.zip</source>
        <source>assets.meta</source>
    </sources>
    <suffix>-${project.version}</suffix>
 </configuration>

 
== Helpful links

http://blogs.aws.amazon.com/security/post/Tx1R9KDN9ISZ0HF/Where-s-my-secret-access-key[How to create AWS user with credentials]

How to create a bucket with public read access [TODO]

How to give user a write access to a bucket [TODO]
